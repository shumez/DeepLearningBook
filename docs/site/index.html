<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="None">
  
  <link rel="shortcut icon" href="img/favicon.ico">
  <title>Home - Deep Learning Book</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link href='https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="css/theme.css" type="text/css" />
  <link rel="stylesheet" href="css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Home";
    var mkdocs_page_input_path = "index.md";
    var mkdocs_page_url = "/";
  </script>
  
  <script src="js/jquery-2.1.1.min.js" defer></script>
  <script src="js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="." class="icon icon-home"> Deep Learning Book</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="tocbase current">
    
    
      


  
    
    <li class="navtree toctree-l1 page current">
      <a class="current" href=".">
        Home
      </a>
    </li>
    
      

  <li class="toctree-l1 current with-children">
    <a href="#contents">
      Contents
      <span class="toctree-expand"></span>
    </a>
  </li>




  
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="01/">01. </a>
  </li>
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="02/">02. </a>
  </li>
    
  </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href=".">Deep Learning Book</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".">Docs</a> &raquo;</li>
    
      
    
    <li>Home</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <!--
Filename:   note.md
Project:    /Users/shume/Developer/DeepLearningBook
Author:     shumez <https://github.com/shumez>
Created:    2018-07-06 13:36:3
Modified:   2019-05-30 18:12:50
-----
Copyright (c) 2019 shumez
-->

<h1 id="deep_learning_book">[Deep Learning Book]<a class="headerlink" href="#deep_learning_book" title="Permanent link">&para;</a></h1>
<p><a href="https://images-na.ssl-images-amazon.com/images/I/61fim5QqaqL._SX373_BO1,204,203,200_.jpg"><img alt="Cover" src="https://images-na.ssl-images-amazon.com/images/I/61fim5QqaqL._SX373_BO1,204,203,200_.jpg" /></a></p>
<h2 id="contents">Contents<a class="headerlink" href="#contents" title="Permanent link">&para;</a></h2>
<ul>
<li>0<ul>
<li><a href="01/">1 Introduction</a><ul>
<li><a href="">1.1 Who Should Read This Book?</a></li>
<li><a href="">1.2 Historical Trends in Deep Learning</a></li>
</ul>
</li>
</ul>
</li>
<li>I Applied Math and Machine Learning Basics<ul>
<li><a href="02/">2 Linear Algebra</a><ul>
<li>2.1 Scalars,Vectors, MatricesandTensors</li>
<li>2.2 Multiplying Matrices and Vectors</li>
<li>2.3 Identity and Inverse Matrices</li>
<li>2.4 Linear Dependence and Span</li>
<li>2.5 Norms</li>
<li>2.6 Special Kinds of Matricesand Vectors</li>
<li>2.7 Eigendecomposition</li>
<li>2.8 Singular Value Decomposition</li>
<li>2.9 The Moore-Penrose Pseudoinverse</li>
<li>2.10 The Trace Operator</li>
<li>2.11 The Determinant</li>
<li>2.12 Example: PrincipalComponentsAnalysis</li>
</ul>
</li>
<li>3 Probability and Information Theory<ul>
<li>3.1 Why Probability?</li>
<li>3.2 Random Variables</li>
<li>3.3 Probability Distributions</li>
<li>3.4 Marginal Probability</li>
<li>3.5 Conditional Probability</li>
<li>3.6 TheChainRuleofConditionalProbabilities</li>
<li>3.7 Independence and Conditional Independence</li>
<li>3.8 Expectation,VarianceandCovariance</li>
<li>3.9 Common Probability Distributions</li>
<li>3.10 UsefulPropertiesofCommonFunctions</li>
<li>3.11 Bayesâ€™ Rule</li>
<li>3.12 Technical Details of Continuous Variables</li>
<li>3.13 Information Theory</li>
<li>3.14 Structured Probabilistic Models</li>
</ul>
</li>
<li>4 Numerical Computation<ul>
<li>4.1 Overflow and Underflow</li>
<li>4.2 Poor Conditioning</li>
<li>4.3 Gradient-Based Optimization</li>
<li>4.4 Constrained Optimization . .</li>
<li>4.5 Example: Linear Least Squares</li>
</ul>
</li>
<li>5 Machine Learning Basics<ul>
<li>5.1 Learning Algorithms</li>
<li>5.2 Capacity,OverfittingandUnderfitting</li>
<li>5.3 HyperparametersandValidationSets</li>
<li>5.4 Estimators, Bias and Variance</li>
<li>5.5 Maximum Likelihood Estimation</li>
<li>5.6 BayesianStatistics</li>
<li>5.7 Supervised Learning Algorithms</li>
<li>5.8 Unsupervised Learning Algorithms</li>
<li>5.9 Stochastic Gradient Descent</li>
<li>5.10 Building a Machine Learning Algorithm</li>
<li>5.11 ChallengesMotivatingDeepLearning</li>
</ul>
</li>
</ul>
</li>
<li>II Deep Networks: Modern Practices<ul>
<li>6 Deep Feedforward Networks<ul>
<li>6.1 Example: Learning XOR</li>
<li>6.2 Gradient-Based Learning</li>
<li>6.3 Hidden Units</li>
<li>6.4 Architecture Design</li>
<li>6.5 Back-Propagation and Other Differentiation Algorithms</li>
<li>6.6 Historical Notes</li>
</ul>
</li>
<li>7 Regularization for Deep Learning<ul>
<li>7.1 Parameter Norm Penalties</li>
<li>7.2 Norm Penalties as Constrained Optimization</li>
<li>7.3 Regularization and Under-Constrained Problems</li>
<li>7.4 Dataset Augmentation</li>
<li>7.5 Noise Robustness</li>
<li>7.6 Semi-Supervised Learning</li>
<li>7.7 Multi-Task Learning</li>
<li>7.8 EarlyStopping</li>
<li>7.9 Parameter Tying and Parameter Sharing</li>
<li>7.10 Sparse Representations</li>
<li>7.11 BaggingandOtherEnsembleMethods</li>
<li>7.12 Dropout</li>
<li>7.13 Adversarial Training</li>
<li>7.14 Tangent Distance, Tangent Prop, and Manifold Tangent Classifier</li>
</ul>
</li>
<li>8 Optimization for Training Deep Models<ul>
<li>8.1 HowLearningDiffersfromPureOptimization</li>
<li>8.2 Challenges in Neural Network Optimization</li>
<li>8.3 Basic Algorithms</li>
<li>8.4 Parameter Initialization Strategies</li>
<li>8.5 AlgorithmswithAdaptiveLearningRates</li>
<li>8.6 Approximate Second-Order Methods</li>
<li>8.7 Optimization Strategies and Meta-Algorithms</li>
</ul>
</li>
<li>9 Convolutional Networks<ul>
<li>9.1 The Convolution Operation</li>
<li>9.2 Motivation</li>
<li>9.3 Pooling</li>
<li>9.4 Convolution and Pooling as an Infinitely Strong Prior</li>
<li>9.5 Variants of the Basic Convolution Function</li>
<li>9.6 Structured Outputs</li>
<li>9.7 Data Types</li>
<li>9.8 Efficient Convolution Algorithms</li>
<li>9.9 Random or Unsupervised Features</li>
<li>9.10 The Neuroscientific Basis for Convolutional Networks</li>
<li>9.11 Convolutional Networks and the History of Deep Learning</li>
</ul>
</li>
<li>10 Sequence Modeling: Recurrent and Recursive Nets<ul>
<li>10.1 Unfolding Computational Graphs</li>
<li>10.2 Recurrent Neural Networks</li>
<li>10.3 Bidirectional RNNs</li>
<li>10.4 Encoder-Decoder Sequence-to-Sequence Architectures</li>
<li>10.5 Deep Recurrent Networks</li>
<li>10.6 Recursive Neural Networks</li>
<li>10.7 TheChallengeofLong-TermDependencies</li>
<li>10.8 Echo State Networks</li>
<li>10.9 Leaky Units and Other Strategies for Multiple Time Scales</li>
<li>10.10 The Long Short-Term Memory and Other Gated RNNs</li>
<li>10.11 Optimization for Long-Term Dependencies</li>
<li>10.12 Explicit Memory</li>
</ul>
</li>
<li>11 Practical Methodology<ul>
<li>11.1 Performance Metrics</li>
<li>11.2 Default Baseline Models</li>
<li>11.3 Determining Whether to Gather More Data</li>
<li>11.4 Selecting Hyperparameters</li>
<li>11.5 Debugging Strategies</li>
<li>11.6 Example: Multi-Digit Number Recognition</li>
</ul>
</li>
<li>12 Applications<ul>
<li>12.1 Large-Scale Deep Learning</li>
<li>12.2 Computer Vision</li>
<li>12.3 Speech Recognition</li>
<li>12.4 Natural Language Processing</li>
<li>12.5 Other Applications</li>
</ul>
</li>
</ul>
</li>
<li>III Deep Learning Research<ul>
<li>13 Linear Factor Models<ul>
<li>13.1 ProbabilisticPCAandFactorAnalysis</li>
<li>13.2 IndependentComponentAnalysis(ICA)</li>
<li>13.3 Slow Feature Analysis</li>
<li>13.4 Sparse Coding</li>
<li>13.5 Manifold Interpretation of PCA</li>
</ul>
</li>
<li>14 Autoencoders<ul>
<li>14.1 Undercomplete Autoencoders</li>
<li>14.2 Regularized Autoencoders</li>
<li>14.3 Representational Power, Layer Size and Depth</li>
<li>14.4 Stochastic Encoders and Decoders</li>
<li>14.5 Denoising Autoencoders</li>
<li>14.6 LearningManifoldswithAutoencoders</li>
<li>14.7 Contractive Autoencoders</li>
<li>14.8 Predictive Sparse Decomposition</li>
<li>14.9 Applications of Autoencoders</li>
</ul>
</li>
<li>15 Representation Learning<ul>
<li>15.1 Greedy Layer-Wise Unsupervised Pretraining</li>
<li>15.2 TransferLearningandDomainAdaptation</li>
<li>15.3 Semi-Supervised Disentangling of Causal Factors</li>
<li>15.4 Distributed Representation</li>
<li>15.5 Exponential Gains from Depth</li>
<li>15.6 Providing Clues to Discover Underlying Causes</li>
</ul>
</li>
<li>16 Structured Probabilistic Models for Deep Learning<ul>
<li>16.1 TheChallengeofUnstructuredModeling</li>
<li>16.2 UsingGraphstoDescribeModelStructure</li>
<li>16.3 Sampling from Graphical Models</li>
<li>16.4 Advantages of Structured Modeling</li>
<li>16.5 Learning about Dependencies</li>
<li>16.6 InferenceandApproximateInference</li>
<li>16.7 The Deep Learning Approach to Structured Probabilistic Models</li>
</ul>
</li>
<li>17 Monte Carlo Methods<ul>
<li>17.1 Sampling and Monte Carlo Methods</li>
<li>17.2 Importance Sampling</li>
<li>17.3 Markov Chain Monte Carlo Methods</li>
<li>17.4 Gibbs Sampling</li>
<li>17.5 The Challenge of Mixing between Separated Modes</li>
</ul>
</li>
<li>18 Confronting the Partition Function<ul>
<li>18.1 The Log-Likelihood Gradient</li>
<li>18.2 Stochastic Maximum Likelihood and Contrastive Divergence</li>
<li>18.3 Pseudolikelihood</li>
<li>18.4 Score Matching and Ratio Matching</li>
<li>18.5 Denoising Score Matching</li>
<li>18.6 Noise-Contrastive Estimation</li>
<li>18.7 Estimating the Partition Function</li>
</ul>
</li>
<li>19 Approximate Inference<ul>
<li>19.1 Inference as Optimization</li>
<li>19.2 Expectation Maximization</li>
<li>19.3 MAP Inference and Sparse Coding</li>
<li>19.4 Variational Inference and Learning</li>
<li>19.5 Learned Approximate Inference</li>
</ul>
</li>
<li>20 Deep Generative Models<ul>
<li>20.1 Boltzmann Machines</li>
<li>20.2 Restricted Boltzmann Machines</li>
<li>20.3 Deep Belief Networks</li>
<li>20.4 Deep Boltzmann Machines</li>
<li>20.5 BoltzmannMachinesforReal-Valued Data</li>
<li>20.6 Convolutional Boltzmann Machines</li>
<li>20.7 Boltzmann Machines for Structured or Sequential Outputs</li>
<li>20.8 Other Boltzmann Machines</li>
<li>20.9 Back-Propagation through Random Operations</li>
<li>20.10 Directed Generative Nets</li>
<li>20.11 Drawing Samples from Autoencoders</li>
<li>20.12 Generative Stochastic Networks</li>
<li>20.13 Other Generation Schemes</li>
<li>20.14 Evaluating Generative Models</li>
<li>20.15 Conclusion</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="_1"><a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<!-- toc -->

<!-- fig -->
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="01/" class="btn btn-neutral float-right" title="01. ">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2018 - 2019 <a href="https://github.com/shumez">shumez</a>
</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
        <span style="margin-left: 15px"><a href="01/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme.js" defer></script>
      <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
      <script src="search/main.js" defer></script>

</body>
</html>

<!--
MkDocs version : 1.0.2
Build Date UTC : 2019-05-30 09:23:21
-->
