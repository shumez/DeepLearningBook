<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>05. Machine Learning Basics - Deep Learning Book</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "05. Machine Learning Basics";
    var mkdocs_page_input_path = "05/index.md";
    var mkdocs_page_url = "/05/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Deep Learning Book</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Part 0.</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../01/">01. Introduction</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Part I. Applied Math and Machine Learning Basics</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../02/">02. Linear Algebra</a>
                </li>
                <li class="">
                    
    <a class="" href="../03/">03. Probability and Information Theory</a>
                </li>
                <li class="">
                    
    <a class="" href="../04/">04. Numerical Computation</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">05. Machine Learning Basics</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#contents">Contents</a></li>
    

    <li class="toctree-l3"><a href="#0500">05.00.</a></li>
    

    <li class="toctree-l3"><a href="#0501_learning_algorithms">05.01. Learning Algorithms</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050101_the_task_t">05.01.01. The Task, T</a></li>
        
            <li><a class="toctree-l4" href="#050102_the_performance_measure_p">05.01.02. The Performance Measure, P</a></li>
        
            <li><a class="toctree-l4" href="#050103_the_experience_e">05.01.03. The Experience, E</a></li>
        
            <li><a class="toctree-l4" href="#050104_example_linear_regression">05.01.04. Example: Linear Regression</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0502_capacity_overfitting_and_underfitting">05.02. Capacity, Overfitting and Underfitting</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050201_the_no_free_lunch_theorem">05.02.01. The No Free Lunch Theorem</a></li>
        
            <li><a class="toctree-l4" href="#050202_regularization">05.02.02. Regularization</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0503_hyperparameters_and_validation_sets">05.03. Hyperparameters and Validation Sets</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050301_cross-validation">05.03.01. Cross-Validation</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0504_estimators_bias_and_variance">05.04. Estimators, Bias and Variance</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050401_point_estimation">05.04.01. Point Estimation</a></li>
        
            <li><a class="toctree-l4" href="#050402_bias">05.04.02. Bias</a></li>
        
            <li><a class="toctree-l4" href="#050403_variance_and_standard_error">05.04.03. Variance and Standard Error</a></li>
        
            <li><a class="toctree-l4" href="#050404_trading_off_bias_and_variance_to_minimize_mean_squared_error">05.04.04. Trading off Bias and Variance to Minimize Mean Squared Error</a></li>
        
            <li><a class="toctree-l4" href="#050405_consistency">05.04.05. Consistency</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0505_maximum_likelihood_estimation">05.05. Maximum Likelihood Estimation</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050501_conditional_log-likelihood_and_mean_squared_error">05.05.01. Conditional Log-Likelihood and Mean Squared Error</a></li>
        
            <li><a class="toctree-l4" href="#050502_properties_of_maximum_likelihood">05.05.02. Properties of Maximum Likelihood</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0506_bayesian_statistics">05.06. Bayesian Statistics</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050601_maximum_a_posteori_map_estimation">05.06.01. Maximum A Posteori (MAP) Estimation</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0507_supervised_learning_algorithm">05.07. Supervised Learning Algorithm</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050701_probabilistic_supervised_learning">05.07.01. Probabilistic Supervised Learning</a></li>
        
            <li><a class="toctree-l4" href="#050702_support_vector_machines">05.07.02. Support Vector Machines</a></li>
        
            <li><a class="toctree-l4" href="#050703_other_simple_supervised_learning_algorithms">05.07.03. Other Simple Supervised Learning Algorithms</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0508_unsupervised_learning_algorithms">05.08. Unsupervised Learning Algorithms</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#050801_principal_components_analysis">05.08.01. Principal Components Analysis</a></li>
        
            <li><a class="toctree-l4" href="#050802_k-means_clustering">05.08.02. k-means Clustering</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#0509_stochastic_gradient_descent">05.09. Stochastic Gradient Descent</a></li>
    

    <li class="toctree-l3"><a href="#0510_building_a_mchine_learning_algorithm">05.10. Building a Mchine Learning Algorithm</a></li>
    

    <li class="toctree-l3"><a href="#0511_challenges_motivating_deep_learning">05.11. Challenges Motivating Deep Learning</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#051101_the_curse_of_dimensionality">05.11.01. The Curse of Dimensionality</a></li>
        
            <li><a class="toctree-l4" href="#051102_local_constancy_and_smoothness_regularization">05.11.02. Local Constancy and Smoothness Regularization</a></li>
        
            <li><a class="toctree-l4" href="#051103_monifold_learning">05.11.03. Monifold Learning</a></li>
        
        </ul>
    

    </ul>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Part II. Deep Networks: Modern Practices</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../06/">06. Deep Feedforward Networks</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Part III. Deep Learning Research</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href=".."></a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Deep Learning Book</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Part I. Applied Math and Machine Learning Basics &raquo;</li>
        
      
    
    <li>05. Machine Learning Basics</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <!--
Filename:   note.md
Project:    /Users/shume/Developer/DeepLearningBook/05
Author:     shumez <https://github.com/shumez>
Created:    2019-06-06 18:02:1
Modified:   2019-06-08 17:27:41
-----
Copyright (c) 2019 shumez
-->

<h1 id="05_machine_learning_basics">05. Machine Learning Basics<a class="headerlink" href="#05_machine_learning_basics" title="Permanent link">&para;</a></h1>
<h2 id="contents">Contents<a class="headerlink" href="#contents" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="#0500">05.00.</a></li>
<li><a href="#0501_learning_algorithms">05.01. Learning Algorithms</a><ul>
<li><a href="#050101_the_task_t">05.01.01. The Task, <script type="math/tex">T</script></a></li>
<li><a href="#050102_the_performance_measure_p">05.01.02. The Performance Measure, <script type="math/tex">P</script></a></li>
<li><a href="#050103_the_experience_e">05.01.03. The Experience, <script type="math/tex">E</script></a></li>
<li><a href="#050104_example_linear_regression">05.01.04. Example: Linear Regression</a></li>
</ul>
</li>
<li><a href="#0502_capacity_overfitting_and_underfitting">05.02. Capacity, Overfitting and Underfitting</a><ul>
<li><a href="#050201_the_no_free_lunch_theorem">05.02.01. The No Free Lunch Theorem</a></li>
<li><a href="#050202_regularization">05.02.02. Regularization</a></li>
</ul>
</li>
<li><a href="#0503_hyperparameters_and_validation_sets">05.03. Hyperparameters and Validation Sets</a><ul>
<li><a href="#050301_cross-validation">05.03.01. Cross-Validation</a></li>
</ul>
</li>
<li><a href="#0504_estimators_bias_and_variance">05.04. Estimators, Bias and Variance</a><ul>
<li><a href="#050401_point_estimation">05.04.01. Point Estimation</a></li>
<li><a href="#050402_bias">05.04.02. Bias</a></li>
<li><a href="#050403_variance_and_standard_error">05.04.03. Variance and Standard Error</a></li>
<li><a href="#050404_trading_off_bias_and_variance_to_minimize_mean_squared_error">05.04.04. Trading off Bias and Variance to Minimize Mean Squared Error</a></li>
<li><a href="#050405_consistency">05.04.05. Consistency</a></li>
</ul>
</li>
<li><a href="#0505_maximum_likelihood_estimation">05.05. Maximum Likelihood Estimation</a><ul>
<li><a href="#050501_conditional_log-likelihood_and_mean_squared_error">05.05.01. Conditional Log-Likelihood and Mean Squared Error</a></li>
<li><a href="#050502_properties_of_maximum_likelihood">05.05.02. Properties of Maximum Likelihood</a></li>
</ul>
</li>
<li><a href="#0506_bayesian_statistics">05.06. Bayesian Statistics</a><ul>
<li><a href="#050601_maximum_a_posteori_map_estimation">05.06.01. Maximum <em>A Posteori</em> (MAP) Estimation</a></li>
</ul>
</li>
<li><a href="#0507_supervised_learning_algorithm">05.07. Supervised Learning Algorithm</a><ul>
<li><a href="#050701_probabilistic_supervised_learning">05.07.01. Probabilistic Supervised Learning</a></li>
<li><a href="#050702_support_vector_machines">05.07.02. Support Vector Machines</a></li>
<li><a href="#050703_other_simple_supervised_learning_algorithms">05.07.03. Other Simple Supervised Learning Algorithms</a></li>
</ul>
</li>
<li><a href="#0508_unsupervised_learning_algorithms">05.08. Unsupervised Learning Algorithms</a><ul>
<li><a href="#050801_principal_components_analysis">05.08.01. Principal Components Analysis</a></li>
<li><a href="#050802_k-means_clustering">05.08.02. <script type="math/tex">k</script>-means Clustering</a></li>
</ul>
</li>
<li><a href="#0509_stochastic_gradient_descent">05.09. Stochastic Gradient Descent</a></li>
<li><a href="#0510_building_a_mchine_learning_algorithm">05.10. Building a Mchine Learning Algorithm</a></li>
<li><a href="#0511_challenges_motivating_deep_learning">05.11. Challenges Motivating Deep Learning</a><ul>
<li><a href="#051101_the_curse_of_dimensionality">05.11.01. The Curse of Dimensionality</a></li>
<li><a href="#051102_local_constancy_and_smoothness_regularization">05.11.02. Local Constancy and Smoothness Regularization</a></li>
<li><a href="#051103_monifold_learning">05.11.03. Monifold Learning</a></li>
</ul>
</li>
</ul>
<h2 id="0500">05.00.<a class="headerlink" href="#0500" title="Permanent link">&para;</a></h2>
<p><a href="#">Murphy (2012)</a>, <a href="#">Bishop (2006)</a></p>
<h2 id="0501_learning_algorithms">05.01. Learning Algorithms<a class="headerlink" href="#0501_learning_algorithms" title="Permanent link">&para;</a></h2>
<p>learn from experience <script type="math/tex">E</script> w respect to tasks <script type="math/tex">T</script> &amp; performance measure <script type="math/tex">P</script>
</p>
<h3 id="050101_the_task_t">05.01.01. The Task, <script type="math/tex">T</script>
<a class="headerlink" href="#050101_the_task_t" title="Permanent link">&para;</a></h3>
<p><strong>classification</strong></p>
<p><strong>classification w missing inputs</strong></p>
<p><strong>regression</strong></p>
<p><strong>transcription</strong></p>
<p><strong>machine translation</strong></p>
<p><strong>structured output</strong></p>
<p><strong>anomaly detection</strong></p>
<p><strong>synthesis and samplint</strong></p>
<p><strong>mputation of missing values</strong></p>
<p><strong>denoising</strong></p>
<p><strong>density estimation</strong> / <strong>probability mass function estimation</strong></p>
<h3 id="050102_the_performance_measure_p">05.01.02. The Performance Measure, <script type="math/tex">P</script>
<a class="headerlink" href="#050102_the_performance_measure_p" title="Permanent link">&para;</a></h3>
<ul>
<li>accuracy</li>
<li>error rate</li>
</ul>
<h3 id="050103_the_experience_e">05.01.03. The Experience, <script type="math/tex">E</script>
<a class="headerlink" href="#050103_the_experience_e" title="Permanent link">&para;</a></h3>
<ul>
<li>unsuprevised</li>
<li>supervised</li>
</ul>
<p>
<script type="math/tex; mode=display"> p(\mathrm{x}) = \prod_{i=1}^n{p(\mathrm{x}_i | \mathrm{x}_1, \cdots, \mathrm{x}_{i-1})} \tag{5.1} </script>
</p>
<p>
<script type="math/tex; mode=display"> p(y | \mathrm{x}) = \frac{p(\mathrm{x}, y)}{\sum_{y'}{p(\mathrm{x}, y')}} \tag{5.2} </script>
</p>
<ul>
<li>reinforcement learning</li>
</ul>
<h3 id="050104_example_linear_regression">05.01.04. Example: Linear Regression<a class="headerlink" href="#050104_example_linear_regression" title="Permanent link">&para;</a></h3>
<p>
<script type="math/tex; mode=display"> \hat{y} = w^T x \tag{5.3} </script>
<script type="math/tex">w \in \mathbb{R}^n </script>
</p>
<p><strong>mean squared error</strong></p>
<p>
<script type="math/tex; mode=display"> \text{MSE}_{\text{text}} = \frac{1}{m} \sum_i{( \hat{y}^{\text{(test)}} - y^{(\text{test})} )_i^2} \tag{5.4} </script>
</p>
<p>
<script type="math/tex; mode=display"> \text{MSE}_{\text{text}} = \frac{1}{m} \Big\| \hat{y}^{\text{(test)}} - y^{(\text{test})} \Big\|_2^2 \tag{5.4} </script>
</p>
<p>to minimize <script type="math/tex">\text{MSE}_{\text{train}}</script>, gradient </p>
<p>
<script type="math/tex; mode=display"> 
    \begin{align*}
        \nabla_w \text{MSE}_{\text{train}} &= 0 \tag{5.6} \\
        \nabla_w \frac{1}{m} \Big\| \hat{y}^{\text{train}} - y^{\text{(train)}} \Big|_2^2 &= 0 \tag{5.7} \\
        \frac{1}{m} \nabla_w \Big\| X^{(\text{train})} w - y^{\text{(train)}} \Big\|_2^2 &= 0 \tag{5.8}
    \end{align*}
</script>
</p>
<p>
<script type="math/tex; mode=display">
    \begin{align*}
        \nabla_w \Big( X^{\text{train}} w - y^{\text{train}} \Big)^T \Big( X^{\text{train}} w - y^{\text{train}} \Big) &= 0 \tag{5.9} \\
        w X^{\text{(train)} T} X^{\text{(train)}} w - 2X^{\text{(train)} T} y^{\text{(train)}} &= 0 \tag{5.11} \\
        w = \Big( X^{\text{(train)} T} X^{\text{(train)}} \Big)^{-1} X^{\text{(train)} T} y^{\text{(train)}} \tag{5.12}
    \end{align*}
</script>
</p>
<p>eq.5.12 <strong>normal eq</strong></p>
<p>
<script type="math/tex; mode=display"> \hat{y} = w^T x + b \tag{5.13} </script>
</p>
<p>bias <script type="math/tex">b</script>
</p>
<h2 id="0502_capacity_overfitting_and_underfitting">05.02. Capacity, Overfitting and Underfitting<a class="headerlink" href="#0502_capacity_overfitting_and_underfitting" title="Permanent link">&para;</a></h2>
<p><strong>generalization</strong></p>
<p><strong>training error</strong>, <strong>generalization error</strong> (<strong>test error</strong>)</p>
<p>
<script type="math/tex; mode=display"> \frac{1}{m^{\text{(train)}}} \Big\| X^{\text{(train)}} w - y^{\text{(train)}} \Big\|_2^2 \tag{5.14} </script>
</p>
<p><strong>statistical learning theory</strong></p>
<p><strong>data generating process</strong><br />
<strong>i.i.d. assumptions</strong><br />
<strong>identically distributed</strong><br />
<strong>data generating distribution</strong></p>
<ol>
<li>make training error small</li>
<li>make gap between training &amp; test error small</li>
</ol>
<p><strong>underfitting</strong><br />
<strong>overfitting</strong></p>
<p><strong>hypothesis space</strong></p>
<p>
<script type="math/tex; mode=display"> \hat{y} = b + wx \tag{5.15} </script>
</p>
<p>
<script type="math/tex; mode=display"> \hat{y} = b + w_1 x + w_2 x^2 \tag{5.16} </script>
</p>
<p>degree 9
<script type="math/tex; mode=display"> \hat{y} = b + \sum_{i=1}^9{w_i x^i} \tag{5.17} </script>
</p>
<p><strong>representational capacity</strong><br />
<strong>effective capacity</strong></p>
<p><strong>Occam's razor</strong></p>
<p><strong>Vapnik-Chervonenkis demension</strong><br />
<strong>non-parametric</strong> models</p>
<p><strong>nearest neighbor regression</strong></p>
<p><strong>Bayes error</strong></p>
<h3 id="050201_the_no_free_lunch_theorem">05.02.01. The No Free Lunch Theorem<a class="headerlink" href="#050201_the_no_free_lunch_theorem" title="Permanent link">&para;</a></h3>
<h3 id="050202_regularization">05.02.02. Regularization<a class="headerlink" href="#050202_regularization" title="Permanent link">&para;</a></h3>
<h2 id="0503_hyperparameters_and_validation_sets">05.03. Hyperparameters and Validation Sets<a class="headerlink" href="#0503_hyperparameters_and_validation_sets" title="Permanent link">&para;</a></h2>
<h3 id="050301_cross-validation">05.03.01. Cross-Validation<a class="headerlink" href="#050301_cross-validation" title="Permanent link">&para;</a></h3>
<h2 id="0504_estimators_bias_and_variance">05.04. Estimators, Bias and Variance<a class="headerlink" href="#0504_estimators_bias_and_variance" title="Permanent link">&para;</a></h2>
<h3 id="050401_point_estimation">05.04.01. Point Estimation<a class="headerlink" href="#050401_point_estimation" title="Permanent link">&para;</a></h3>
<h3 id="050402_bias">05.04.02. Bias<a class="headerlink" href="#050402_bias" title="Permanent link">&para;</a></h3>
<h3 id="050403_variance_and_standard_error">05.04.03. Variance and Standard Error<a class="headerlink" href="#050403_variance_and_standard_error" title="Permanent link">&para;</a></h3>
<h3 id="050404_trading_off_bias_and_variance_to_minimize_mean_squared_error">05.04.04. Trading off Bias and Variance to Minimize Mean Squared Error<a class="headerlink" href="#050404_trading_off_bias_and_variance_to_minimize_mean_squared_error" title="Permanent link">&para;</a></h3>
<h3 id="050405_consistency">05.04.05. Consistency<a class="headerlink" href="#050405_consistency" title="Permanent link">&para;</a></h3>
<h2 id="0505_maximum_likelihood_estimation">05.05. Maximum Likelihood Estimation<a class="headerlink" href="#0505_maximum_likelihood_estimation" title="Permanent link">&para;</a></h2>
<h3 id="050501_conditional_log-likelihood_and_mean_squared_error">05.05.01. Conditional Log-Likelihood and Mean Squared Error<a class="headerlink" href="#050501_conditional_log-likelihood_and_mean_squared_error" title="Permanent link">&para;</a></h3>
<h3 id="050502_properties_of_maximum_likelihood">05.05.02. Properties of Maximum Likelihood<a class="headerlink" href="#050502_properties_of_maximum_likelihood" title="Permanent link">&para;</a></h3>
<h2 id="0506_bayesian_statistics">05.06. Bayesian Statistics<a class="headerlink" href="#0506_bayesian_statistics" title="Permanent link">&para;</a></h2>
<h3 id="050601_maximum_a_posteori_map_estimation">05.06.01. Maximum <em>A Posteori</em> (MAP) Estimation<a class="headerlink" href="#050601_maximum_a_posteori_map_estimation" title="Permanent link">&para;</a></h3>
<h2 id="0507_supervised_learning_algorithm">05.07. Supervised Learning Algorithm<a class="headerlink" href="#0507_supervised_learning_algorithm" title="Permanent link">&para;</a></h2>
<h3 id="050701_probabilistic_supervised_learning">05.07.01. Probabilistic Supervised Learning<a class="headerlink" href="#050701_probabilistic_supervised_learning" title="Permanent link">&para;</a></h3>
<h3 id="050702_support_vector_machines">05.07.02. Support Vector Machines<a class="headerlink" href="#050702_support_vector_machines" title="Permanent link">&para;</a></h3>
<h3 id="050703_other_simple_supervised_learning_algorithms">05.07.03. Other Simple Supervised Learning Algorithms<a class="headerlink" href="#050703_other_simple_supervised_learning_algorithms" title="Permanent link">&para;</a></h3>
<h2 id="0508_unsupervised_learning_algorithms">05.08. Unsupervised Learning Algorithms<a class="headerlink" href="#0508_unsupervised_learning_algorithms" title="Permanent link">&para;</a></h2>
<h3 id="050801_principal_components_analysis">05.08.01. Principal Components Analysis<a class="headerlink" href="#050801_principal_components_analysis" title="Permanent link">&para;</a></h3>
<h3 id="050802_k-means_clustering">05.08.02. <script type="math/tex">k</script>-means Clustering<a class="headerlink" href="#050802_k-means_clustering" title="Permanent link">&para;</a></h3>
<h2 id="0509_stochastic_gradient_descent">05.09. Stochastic Gradient Descent<a class="headerlink" href="#0509_stochastic_gradient_descent" title="Permanent link">&para;</a></h2>
<h2 id="0510_building_a_mchine_learning_algorithm">05.10. Building a Mchine Learning Algorithm<a class="headerlink" href="#0510_building_a_mchine_learning_algorithm" title="Permanent link">&para;</a></h2>
<h2 id="0511_challenges_motivating_deep_learning">05.11. Challenges Motivating Deep Learning<a class="headerlink" href="#0511_challenges_motivating_deep_learning" title="Permanent link">&para;</a></h2>
<h3 id="051101_the_curse_of_dimensionality">05.11.01. The Curse of Dimensionality<a class="headerlink" href="#051101_the_curse_of_dimensionality" title="Permanent link">&para;</a></h3>
<h3 id="051102_local_constancy_and_smoothness_regularization">05.11.02. Local Constancy and Smoothness Regularization<a class="headerlink" href="#051102_local_constancy_and_smoothness_regularization" title="Permanent link">&para;</a></h3>
<h3 id="051103_monifold_learning">05.11.03. Monifold Learning<a class="headerlink" href="#051103_monifold_learning" title="Permanent link">&para;</a></h3>
<h2 id="_1"><a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<!-- toc -->

<!-- ref -->

<!-- fig -->

<!-- term -->

<style type="text/css">
    img{width: 51%; float: right;}
</style>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../06/" class="btn btn-neutral float-right" title="06. Deep Feedforward Networks">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../04/" class="btn btn-neutral" title="04. Numerical Computation"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2018 - 2019 <a href="https://github.com/shumez">shumez</a>
</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../04/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../06/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
